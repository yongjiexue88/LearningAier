name: Deploy Backend to Cloud Run (Lab)

on:
  push:
    branches:
      - main
  # You can also trigger manually from GitHub Actions tab
  workflow_dispatch:

env:
  PROJECT_ID: learningaier-lab
  REGION: us-central1
  SERVICE_NAME: learningaier-api-lab
  REPO_NAME: backend-api-lab

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Google Auth
        id: auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: '${{ secrets.GCP_SA_KEY_LAB }}'

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Build and Push Container
        run: |
          cd backend-fastapi
          gcloud builds submit --tag gcr.io/${{ env.PROJECT_ID }}/${{ env.REPO_NAME }} --async
          
      - name: Wait for Build
        run: |
          # Get the latest build ID
          BUILD_ID=$(gcloud builds list --limit=1 --format="value(id)")
          echo "Waiting for build $BUILD_ID to complete..."
          
          # Poll until build completes
          while true; do
            STATUS=$(gcloud builds describe $BUILD_ID --format="value(status)")
            echo "Build status: $STATUS"
            
            if [ "$STATUS" = "SUCCESS" ]; then
              echo "Build completed successfully!"
              break
            elif [ "$STATUS" = "FAILURE" ] || [ "$STATUS" = "TIMEOUT" ] || [ "$STATUS" = "CANCELLED" ]; then
              echo "Build failed with status: $STATUS"
              exit 1
            fi
            
            sleep 10
          done

      - name: Prepare Secrets
        id: secrets
        env:
          FIREBASE_JSON: ${{ secrets.FIREBASE_CREDENTIALS_JSON }}
        run: |
          echo "FIREBASE_CREDENTIALS_BASE64=$(echo "$FIREBASE_JSON" | base64 -w 0)" >> $GITHUB_OUTPUT

      - name: Deploy to Cloud Run
        run: |
          gcloud run deploy ${{ env.SERVICE_NAME }} \
            --image gcr.io/${{ env.PROJECT_ID }}/${{ env.REPO_NAME }} \
            --platform managed \
            --region ${{ env.REGION }} \
            --allow-unauthenticated \
            --timeout=300 \
            --cpu-boost \
            --set-env-vars "APP_ENV=lab" \
            --set-env-vars "FIREBASE_PROJECT_ID=${{ secrets.VITE_FIREBASE_PROJECT_ID }}" \
            --set-env-vars "FIREBASE_STORAGE_BUCKET=${{ secrets.VITE_FIREBASE_STORAGE_BUCKET }}" \
            --set-env-vars "FIREBASE_CREDENTIALS_JSON=${{ steps.secrets.outputs.FIREBASE_CREDENTIALS_BASE64 }}" \
            --set-env-vars "LLM_PROVIDER=vertex_ai" \
            --set-env-vars "LLM_MODEL=gemini-2.0-flash-exp" \
            --set-env-vars "LLM_API_KEY=${{ secrets.LLM_API_KEY }}" \
            --set-env-vars "VERTEX_PROJECT_ID=learningaier-lab" \
            --set-env-vars "VERTEX_LOCATION=us-central1" \
            --set-env-vars "VERTEX_GEMINI_MODEL=gemini-2.0-flash-exp" \
            --set-env-vars "VERTEX_EMBEDDING_MODEL=text-embedding-004" \
            --set-env-vars "EMBEDDINGS_PROVIDER=gemini" \
            --set-env-vars "EMBEDDINGS_MODEL=text-embedding-004" \
            --set-env-vars "EMBEDDINGS_API_KEY=${{ secrets.LLM_API_KEY }}" \
            --set-env-vars "EMBEDDINGS_DIMENSIONS=768" \
            --set-env-vars "VECTOR_DB_PROVIDER=pinecone" \
            --set-env-vars "PINECONE_API_KEY=${{ secrets.PINECONE_API_KEY }}" \
            --set-env-vars "PINECONE_INDEX_NAME=learningaier-index" \
            --set-env-vars "PINECONE_INDEX_HOST=${{ secrets.PINECONE_INDEX_HOST }}" \
            --set-env-vars "PINECONE_ENVIRONMENT=us-east-1"

